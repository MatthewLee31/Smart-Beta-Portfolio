{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smart Beta Portfolio Optimization Project\n",
    "\n",
    "## Portfolio Construction Overview\n",
    "\n",
    "\n",
    "- Objective 1:   Minimize portfolio variance\n",
    "- Objective 2:   Smart beta portfolio can match the returns of an index with less volatility (higher risk-adjusted return)\n",
    "- Methodology:   The Smart Beta Portfolio weightings is based on the amounts of dividends issued, not the market capitalization\n",
    "- Constraints:   The Smart Beta Portfolio is long-only\n",
    "- Evaluation :   The Smart Beta Portfolio will be compared to the performance of the ETF.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Universe\n",
    "\n",
    "- The larger dollar volume stocks is selected as the research universe because they are highly liquid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../data/project_3/eod-quotemedia.csv')\n",
    "\n",
    "percent_top_dollar = 0.2\n",
    "high_volume_symbols = project_helper.large_dollar_volume_stocks(df, 'adj_close', 'adj_volume', percent_top_dollar)\n",
    "df = df[df['ticker'].isin(high_volume_symbols)]\n",
    "\n",
    "close = df.reset_index().pivot(index='date', columns='ticker', values='adj_close')\n",
    "volume = df.reset_index().pivot(index='date', columns='ticker', values='adj_volume')\n",
    "dividends = df.reset_index().pivot(index='date', columns='ticker', values='dividends')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smart Beta Portfolio\n",
    "\n",
    "- Methodology: Portfolio weights are based on dividend yields. This portfolio will then be compared to the market cap weighted index to see how well it performs. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dollar_volume_weights(close, volume):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    close : DataFrame\n",
    "        Close price for each ticker and date\n",
    "    volume : str\n",
    "        Volume for each ticker and date\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dollar_volume_weights : DataFrame\n",
    "        The dollar volume weights for each ticker and date\n",
    "    \"\"\"\n",
    "    assert close.index.equals(volume.index)\n",
    "    assert close.columns.equals(volume.columns)\n",
    "    \n",
    "    new_list = []\n",
    "    new_vol = close * volume\n",
    "    \n",
    "    for i, row in new_vol.iterrows():\n",
    "        new_list.append(row.sum())\n",
    "    new_vol['sum'] = new_list\n",
    "    dollar_volume_weights = new_vol.iloc[:,:-1].div(new_vol['sum'].values,axis=0)\n",
    "    return dollar_volume_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_weights = generate_dollar_volume_weights(close, volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_dividend_weights(dividends):\n",
    "    \"\"\"\n",
    "    Calculate dividend weights.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dividends : DataFrame\n",
    "        Dividend for each stock and date\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dividend_weights : DataFrame\n",
    "        Weights for each stock and date\n",
    "    \"\"\"\n",
    "    \n",
    "    dividend_weights = np.cumsum(dividends)\n",
    "    dividend_weights['sum'] = dividend_weights.sum(axis=1)\n",
    "    dividend_weights = dividend_weights.iloc[:,:-1].div(dividend_weights[\"sum\"].values,axis=0)\n",
    "    \n",
    "\n",
    "    return dividend_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etf_weights = calculate_dividend_weights(dividends)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Returns\n",
    "- Generate returns data for all the stocks and dates from price data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_returns(prices):\n",
    "    \"\"\"\n",
    "    Generate returns for ticker and date.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    prices : DataFrame\n",
    "        Price for each ticker and date\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    returns : Dataframe\n",
    "        The returns for each ticker and date\n",
    "    \"\"\"\n",
    "    \n",
    "    return (prices - prices.shift(1)) / prices.shift(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "returns = generate_returns(close)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighted Returns\n",
    "\n",
    "- Create weighted returns using the returns and weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_weighted_returns(returns, weights):\n",
    "    \"\"\"\n",
    "    Generate weighted returns.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    returns : DataFrame\n",
    "        Returns for each ticker and date\n",
    "    weights : DataFrame\n",
    "        Weights for each ticker and date\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    weighted_returns : DataFrame\n",
    "        Weighted returns for each ticker and date\n",
    "    \"\"\"\n",
    "    assert returns.index.equals(weights.index)\n",
    "    assert returns.columns.equals(weights.columns)\n",
    "    \n",
    "    weighted_returns = returns * weights\n",
    "\n",
    "    return weighted_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_weighted_returns = generate_weighted_returns(returns, index_weights)\n",
    "etf_weighted_returns = generate_weighted_returns(returns, etf_weights)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cumulative Returns\n",
    "- Calculate the cumulative returns over time given the returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cumulative_returns(returns):\n",
    "    \"\"\"\n",
    "    Calculate cumulative returns.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    returns : DataFrame\n",
    "        Returns for each ticker and date\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    cumulative_returns : Pandas Series\n",
    "        Cumulative returns for each date\n",
    "    \"\"\"\n",
    "    return returns.sum(axis=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_weighted_cumulative_returns = calculate_cumulative_returns(index_weighted_returns)\n",
    "etf_weighted_cumulative_returns = calculate_cumulative_returns(etf_weighted_returns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracking Error\n",
    "\n",
    "- Annualized tracking error between the portfolio and the index\n",
    "\n",
    "Formula is as follows:\n",
    "$$ TE = \\sqrt{252} * SampleStdev(r_p - r_b) $$\n",
    "\n",
    "Where $ r_p $ is the portfolio/ETF returns and $ r_b $ is the benchmark returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tracking_error(benchmark_returns_by_date, etf_returns_by_date):\n",
    "    \"\"\"\n",
    "    Calculate the tracking error.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    benchmark_returns_by_date : Pandas Series\n",
    "        The benchmark returns for each date\n",
    "    etf_returns_by_date : Pandas Series\n",
    "        The ETF returns for each date\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tracking_error : float\n",
    "        The tracking error\n",
    "    \"\"\"\n",
    "    assert benchmark_returns_by_date.index.equals(etf_returns_by_date.index)\n",
    "    return np.sqrt(252) * np.std(etf_returns_by_date - benchmark_returns_by_date, ddof=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smart Beta Tracking Error: 0.1020761483200753\n"
     ]
    }
   ],
   "source": [
    "smart_beta_tracking_error = tracking_error(np.sum(index_weighted_returns, 1), np.sum(etf_weighted_returns, 1))\n",
    "print('Smart Beta Tracking Error: {}'.format(smart_beta_tracking_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Portfolio Optimization: Part 2\n",
    "\n",
    "Create second portfolio. This portfolio shall be independent of the dividend-weighted portfolio that we created in part 1.\n",
    "\n",
    "- Some investors evaluate a fund by looking at how well it tracks its index. However, the fund is still expected to deviate from the index within a certain range in order to improve fund performance. \n",
    "\n",
    "- Objective: minimize the portfolio variance and closely track a market cap weighted index.  Hence, objectivve is to minimize the distance between the weights of our portfolio and the weights of the index.\n",
    "\n",
    "$Minimize \\left [ \\sigma^2_p + \\lambda \\sqrt{\\sum_{1}^{m}(weight_i - indexWeight_i)^2} \\right  ]$ where $m$ is the number of stocks in the portfolio, and $\\lambda$ is a scaling factor (hyperparameter).\n",
    "\n",
    "- By minimizing a linear combination of both the portfolio risk and distance between portfolio and benchmark weights, we attempt to balance the desire to minimize portfolio variance with the goal of tracking the index."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Covariance\n",
    "-  Calculate the covariance of the returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.89856076  0.7205586   0.8458721 ]\n",
      " [ 0.7205586   0.78707297  0.76450378]\n",
      " [ 0.8458721   0.76450378  0.83182775]]\n",
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def get_covariance_returns(returns):\n",
    "    \"\"\"\n",
    "    Calculate covariance matrices.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    returns : DataFrame\n",
    "        Returns for each ticker and date\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    returns_covariance  : 2 dimensional Ndarray\n",
    "        The covariance of the returns\n",
    "    \"\"\"\n",
    "    #TODO: Implement function\n",
    "    returns_copy = returns.copy()\n",
    "    returns_copy.fillna(0, inplace=True)\n",
    "    returns_covariance = np.cov(returns_copy.T)\n",
    "    print(returns_covariance)\n",
    "    \n",
    "    return returns_covariance\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  5.31791451e-04   7.21251856e-05   9.55847963e-05 ...,   4.55526842e-05\n",
      "    1.26756746e-04   4.27885833e-05]\n",
      " [  7.21251856e-05   2.14185487e-04   4.87000321e-05 ...,   3.43023358e-05\n",
      "    8.17766960e-05   4.13786801e-05]\n",
      " [  9.55847963e-05   4.87000321e-05   2.64537496e-04 ...,   3.32734532e-05\n",
      "    1.11616723e-04   5.40669112e-05]\n",
      " ..., \n",
      " [  4.55526842e-05   3.43023358e-05   3.32734532e-05 ...,   1.14424083e-04\n",
      "    3.48568802e-05   2.79122492e-05]\n",
      " [  1.26756746e-04   8.17766960e-05   1.11616723e-04 ...,   3.48568802e-05\n",
      "    7.17162013e-04   8.42633668e-05]\n",
      " [  4.27885833e-05   4.13786801e-05   5.40669112e-05 ...,   2.79122492e-05\n",
      "    8.42633668e-05   1.29561995e-04]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "The graph for Covariance Returns Correlation Matrix is too large. You can view it <a href=\"graphs/CovarianceReturnsCorrelationMatrix.html\" target=\"_blank\">here</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "covariance_returns = get_covariance_returns(returns)\n",
    "covariance_returns = pd.DataFrame(covariance_returns, index = returns.columns, columns = returns.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Portfolio variance\n",
    "Formula: $\\sigma^2_p = \\mathbf{x^T} \\mathbf{P} \\mathbf{x}$\n",
    "\n",
    "### Distance from index weights\n",
    "L2 norm.  $\\sqrt{\\sum_{1}^{n}(weight_i - indexWeight_i)^2}$  or $\\left \\| \\mathbf{x} - \\mathbf{index} \\right \\|_2$.\n",
    "\n",
    "### Objective function\n",
    "-  minimize both the portfolio variance and the distance of the portfolio weights from the index weights. Choose hyperparameter ('lambda')\n",
    "\n",
    "### Constraints\n",
    "Go long only.  Constaint =  [x >= 0, sum(x) == 1]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimized Portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_optimal_single_rebalance_etf_weights = get_optimal_weights(covariance_returns.values, index_weights.iloc[-1])\n",
    "optimal_single_rebalance_etf_weights = pd.DataFrame(\n",
    "    np.tile(raw_optimal_single_rebalance_etf_weights, (len(returns.index), 1)),\n",
    "    returns.index,\n",
    "    returns.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our ETF weights built, let's compare it to the index. Run the next cell to calculate the ETF returns and compare it to the index returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim_etf_returns = generate_weighted_returns(returns, optimal_single_rebalance_etf_weights)\n",
    "optim_etf_cumulative_returns = calculate_cumulative_returns(optim_etf_returns)\n",
    "project_helper.plot_benchmark_returns(index_weighted_cumulative_returns, optim_etf_cumulative_returns, 'Optimized ETF vs Index')\n",
    "\n",
    "optim_etf_tracking_error = tracking_error(np.sum(index_weighted_returns, 1), np.sum(optim_etf_returns, 1))\n",
    "print('Optimized ETF Tracking Error: {}'.format(optim_etf_tracking_error))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
